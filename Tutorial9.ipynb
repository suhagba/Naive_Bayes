{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name:** \\_\\_\\_\\_\\_\n",
    "\n",
    "**EID:** \\_\\_\\_\\_\\_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS4487 - Tutorial 9\n",
    "## Face Detection with CNNs\n",
    "\n",
    "In this tutorial you will train a CNN to detect whether there is a face in a small image patch.\n",
    "\n",
    "First we need to initialize Python.  Run the below cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\sklearn\\lda.py:4: DeprecationWarning: lda.LDA has been moved to discriminant_analysis.LinearDiscriminantAnalysis in 0.17 and will be removed in 0.19\n",
      "  \"in 0.17 and will be removed in 0.19\", DeprecationWarning)\n",
      "C:\\Anaconda2\\lib\\site-packages\\sklearn\\qda.py:4: DeprecationWarning: qda.QDA has been moved to discriminant_analysis.QuadraticDiscriminantAnalysis in 0.17 and will be removed in 0.19.\n",
      "  \"in 0.17 and will be removed in 0.19.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import IPython.core.display         \n",
    "# setup output image format (Chrome works best)\n",
    "IPython.core.display.set_matplotlib_formats(\"svg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from numpy import *\n",
    "from sklearn import *\n",
    "import glob\n",
    "import os\n",
    "import IPython.utils.warn as warn\n",
    "random.seed(100)\n",
    "import skimage.io\n",
    "import skimage.color\n",
    "import skimage.transform\n",
    "from scipy import ndimage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will load scikit-neuralnetwork and set 32-bit CPU mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name gof",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-2b41ac09d1c3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msknn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplatform\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcpu32\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[1;32mfrom\u001b[0m \u001b[0msknn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmlp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlogging\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbasicConfig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mstruct\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda2\\lib\\site-packages\\sknn\\mlp.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[1;32mimport\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbase\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda2\\lib\\site-packages\\theano\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmisc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msafe_asarray\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_asarray\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m \u001b[1;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprinting\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpprint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscan_module\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mscan\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfoldl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfoldr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Anaconda2\\lib\\site-packages\\theano\\printing.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[1;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mgof\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtheano\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgof\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mOp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mApply\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name gof"
     ]
    }
   ],
   "source": [
    "from sknn.platform import cpu32\n",
    "from sknn import mlp\n",
    "import logging\n",
    "logging.basicConfig()\n",
    "import struct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading Data and Pre-processing\n",
    "Next we need to load the images.  Download `faces.zip`, and unzip it in the same directory as this ipynb file.  Then run the following cell to load the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filelist = glob.glob('faces/*/*/*.png')\n",
    "\n",
    "if len(filelist) == 0:\n",
    "    warn.error(\"Could not find images in faces directory!  \" + \n",
    "               \"Make sure you put it here: \" + os.getcwd() )\n",
    "else:\n",
    "    imgdata = {'train':[], 'test':[]}\n",
    "    classes = {'train':[], 'test':[]}\n",
    "\n",
    "    for f in filelist:\n",
    "        # read image: range is [0,1]\n",
    "        img = skimage.io.imread(f)\n",
    "        # convert to grayscale\n",
    "        img = skimage.color.rgb2gray(img)\n",
    "\n",
    "        # filename is : faces/train/face/fname.png\n",
    "        (fdir1, fname)  = os.path.split(f)     # get file name\n",
    "        (fdir2, fclass) = os.path.split(fdir1) # get class (face, nonface)\n",
    "        (fdir3, fset)   = os.path.split(fdir2) # get training/test set\n",
    "        \n",
    "        # class 1 = face; class 0 = non-face\n",
    "        myclass = int(fclass == \"face\")  \n",
    "\n",
    "        imgdata[fset].append(img)\n",
    "        classes[fset].append(myclass)\n",
    "    imgsize = img.shape\n",
    "\n",
    "    \n",
    "# remove some non-face test cases to balance the test set\n",
    "testclass2start = sum(classes['test'])\n",
    "imgdata['test']  = imgdata['test'][:2*testclass2start]\n",
    "classes['test']  = classes['test'][:2*testclass2start]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will convert the list of images into a block (array) of images for easier processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# convert list to numpy array\n",
    "trainY = asarray(classes['train'])  \n",
    "testY  = asarray(classes['test'])\n",
    "\n",
    "# convert list of ndarray to ndarray\n",
    "trainI = asarray(imgdata['train'])\n",
    "testI  = asarray(imgdata['test'])\n",
    "\n",
    "# cleanup memory\n",
    "del imgdata\n",
    "\n",
    "# shuffle the data (since it is in order by class)\n",
    "random.seed(123)\n",
    "inds1 = random.permutation(len(trainI)).tolist()\n",
    "inds2 = random.permutation(len(testI)).tolist()\n",
    "trainY = trainY[inds1]\n",
    "testY  = testY[inds2]\n",
    "trainI = trainI[inds1]\n",
    "testI = testI[inds2]\n",
    "\n",
    "print trainI.shape\n",
    "print testI.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each image is a 19x19 array of pixel values.  Run the below code to show an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print img.shape\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(trainI[1], cmap='gray', interpolation='nearest')\n",
    "plt.title(\"face sample\")\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(trainI[2], cmap='gray', interpolation='nearest')\n",
    "plt.title(\"non-face sample\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the below code to show more images!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# function to make an image montage\n",
    "def image_montage(X, imsize=None, maxw=10):\n",
    "    \"\"\"X can be a list of images, or a matrix of vectorized images.\n",
    "      Specify imsize when X is a matrix.\"\"\"\n",
    "    tmp = []\n",
    "    numimgs = len(X)\n",
    "    \n",
    "    # create a list of images (reshape if necessary)\n",
    "    for i in range(0,numimgs):\n",
    "        if imsize != None:\n",
    "            tmp.append(X[i].reshape(imsize))\n",
    "        else:\n",
    "            tmp.append(X[i])\n",
    "    \n",
    "    # add blanks\n",
    "    if (numimgs > maxw) and (mod(numimgs, maxw) > 0):\n",
    "        leftover = maxw - mod(numimgs, maxw)\n",
    "        meanimg = 0.5*(X[0].max()+X[0].min())\n",
    "        for i in range(0,leftover):\n",
    "            tmp.append(ones(tmp[0].shape)*meanimg)\n",
    "    \n",
    "    # make the montage\n",
    "    tmp2 = []\n",
    "    for i in range(0,len(tmp),maxw):\n",
    "        tmp2.append( hstack(tmp[i:i+maxw]) )\n",
    "    montimg = vstack(tmp2) \n",
    "    return montimg\n",
    "\n",
    "# show images in a plot\n",
    "def show_imgs(W_list, nc=10, highlight_green=None, highlight_red=None, titles=None):\n",
    "    # nc is the number of columns\n",
    "    nfilter = len(W_list)\n",
    "    nr = (nfilter - 1) // nc + 1\n",
    "    for i in range(nr):\n",
    "        for j in range(nc):\n",
    "            idx = i * nc + j\n",
    "            if idx == nfilter:\n",
    "                break\n",
    "            plt.subplot(nr, nc, idx + 1)\n",
    "            cur_W = W_list[idx]\n",
    "            plt.imshow(cur_W,cmap='gray', interpolation='nearest')  \n",
    "            if titles is not None:\n",
    "                if isinstance(titles, basestring):\n",
    "                    plt.title(titles % idx)\n",
    "                else:\n",
    "                    plt.title(titles[idx])\n",
    "            \n",
    "            if ((highlight_green is not None) and highlight_green[idx]) or \\\n",
    "               ((highlight_red is not None) and highlight_red[idx]): \n",
    "                ax = plt.gca()\n",
    "                if highlight_green[idx]:\n",
    "                    mycol = '#00FF00'\n",
    "                else:\n",
    "                    mycol = 'r'\n",
    "                for S in ['bottom', 'top', 'right', 'left']:\n",
    "                    ax.spines[S].set_color(mycol)\n",
    "                    ax.spines[S].set_lw(2.0)\n",
    "                ax.xaxis.set_ticks_position('none')               \n",
    "                ax.yaxis.set_ticks_position('none')\n",
    "                ax.set_xticks([])\n",
    "                ax.set_yticks([])\n",
    "            else:\n",
    "                plt.gca().set_axis_off()\n",
    "\n",
    "# show a few images\n",
    "plt.figure(figsize=(9,4))\n",
    "plt.imshow(image_montage(trainI[trainY==0][0:50]), cmap='gray', interpolation='nearest')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(9,4))\n",
    "plt.imshow(image_montage(trainI[trainY==1][0:50]), cmap='gray', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we will generate the training/validation set from the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# generate fixed validation set of 10% of the training set\n",
    "vtrainI, validI, vtrainY, validY = \\\n",
    "  cross_validation.train_test_split(trainI, trainY, \n",
    "  train_size=0.9, test_size=0.1, random_state=4488)\n",
    "\n",
    "# make validation data\n",
    "# - sknn expects the validation data shape to be: (N, C, Y, X)\n",
    "# - N=number of images, C=color channels, Y=height, X=width\n",
    "# we reshape the gray-scale (N, Y, X) to (N, 1, Y, X)\n",
    "validsetI = (validI.reshape((validI.shape[0], 1, validI.shape[1], validI.shape[2])), \n",
    "             validY)\n",
    "\n",
    "print vtrainI.shape\n",
    "print validI.shape\n",
    "print validsetI[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we define some useful functions for recording the training/validation error after each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nnstats = {}  # dictionary for storing stats\n",
    "\n",
    "def reset_stats(X, **_):\n",
    "    # reset the statistics\n",
    "    global nnstats\n",
    "    nnstats['valid_error'] = []\n",
    "    nnstats['train_error'] = []\n",
    "\n",
    "def store_stats(avg_valid_error, avg_train_error, **_):\n",
    "    # store the statistics after each iteration\n",
    "    nnstats['valid_error'].append(avg_valid_error)\n",
    "    nnstats['train_error'].append(avg_train_error)\n",
    "    # print an update after 10 iterations\n",
    "    if mod(len(nnstats['valid_error']), 10) == 0:\n",
    "        print \"iter %d: train=%0.4g; valid=%0.4g\" % \\\n",
    "          (len(nnstats['valid_error']), nnstats['train_error'][-1], nnstats['valid_error'][-1])\n",
    "    \n",
    "def plot_nnstats(nnstats):    \n",
    "    # plot the statistics\n",
    "    plt.plot(nnstats['train_error'], label=\"training loss (%g)\" % nnstats['train_error'][-1])\n",
    "    plt.plot(nnstats['valid_error'], label=\"validation loss (%g)\" % nnstats['valid_error'][-1])\n",
    "    plt.grid(True)\n",
    "    plt.legend(loc=\"best\", fontsize=9)\n",
    "\n",
    "# setup the callbacks\n",
    "callbacks = {'on_epoch_finish': store_stats, \n",
    "             'on_train_start': reset_stats\n",
    "            }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Detection using NN\n",
    "\n",
    "Train a CNN to classify an image patch as face or not face.  Use  `vtrainI` and `vtrainY` as the training set and `validsetI` as the validation set.  You can try different architectures, and adjust values of the learning rates, number of iterations, weight decay, and dropout rate to get a good result.  Use a large batch size (e.g., 50) to speed up the training time.  Remember to add the `callbacks` so that you can monitor the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### INSERT YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_How does the CNN compare to the linear and non-linear classifiers that you tried in Tutorial 4?_\n",
    "- **INSERT YOUR ANSWER HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Augmentation\n",
    "\n",
    "Augmenting the training data with permutations is a good way to prevent NN from overfitting, and improving their generalization.  We will use two functions to augment the data in a batch when a batch starts, and reset the data when the batch ends.  A new callback dictionary `callbacks_aug` is defined to perform the augmentation during the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# global variable to save batch data before augmentation\n",
    "savedXb = array([])\n",
    "\n",
    "def augment_batch(Xb, yb, **vars):\n",
    "    # Xb and yb are the data for the current batch   \n",
    "    \n",
    "    # first, make a copy of the original data \n",
    "    global savedXb\n",
    "    savedXb = Xb.copy()  \n",
    "    \n",
    "    # second, add permutations to the data (you will write this function later)\n",
    "    Xb[:] = add_noise(Xb) \n",
    "\n",
    "def reset_batch(Xb, yb, **vars):\n",
    "    # reset the batch data to the saved data\n",
    "    global savedXb\n",
    "    Xb[:] = savedXb\n",
    "\n",
    "# setup the callback dictionary\n",
    "callbacks_aug = {'on_epoch_finish': store_stats, \n",
    "                 'on_train_start': reset_stats,\n",
    "                 'on_batch_start': augment_batch, # augment at start of batch\n",
    "                 'on_batch_finish': reset_batch,  # reset the batch data\n",
    "               }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define a few functions for adding noise or permuting the data.  The following functions are provided: 1) add Gaussian pixel noise; 2) add corruption noise (setting some input pixels to 0); 3) scale and shift pixel values (changing contrast and brightness); 4) mirror flip horizontally; 5) and translate horizontally and vertically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_gauss_noise(X, sigma2=0.03):\n",
    "    # add Gaussian noise with zero mean, and variance sigma2\n",
    "    return X + random.normal(0, sigma2, X.shape)\n",
    "\n",
    "def add_corrupt_noise(X, p=0.1):\n",
    "    # apply pixel corruption (zero out value) with probability p\n",
    "    return X * random.binomial(1, 1-p, X.shape)\n",
    "\n",
    "def add_scale_shift(X, sigma2=0.1, alpha2=0.2):\n",
    "    # randomly scale and shift the pixel values (same for each image)\n",
    "    # Xnew = a X + b\n",
    "    # a is sampled from a Gaussian with mean 1, and variance sigma2\n",
    "    # b is sampled from a Gaussian with mean 0, and variance alpha2\n",
    "    if X.ndim == 3:\n",
    "        dshape = (X.shape[0],1,1)\n",
    "    elif X.ndim == 4:\n",
    "        dshape = (X.shape[0],1,1,1)\n",
    "    else:\n",
    "        dshape = (1,)\n",
    "    a = random.normal(1,sigma2, dshape)\n",
    "    b = random.normal(0,alpha2, dshape)\n",
    "    return minimum(maximum( a*X + b, 0.0), 1.0)\n",
    "\n",
    "def add_flip(X):  \n",
    "    # randomly horizontally flip all images with 50% probability\n",
    "    f = random.binomial(1, 0.5)\n",
    "    if f==1:\n",
    "        return X[...,::-1]\n",
    "    else:\n",
    "        return X\n",
    "\n",
    "def add_translate(X, maxT=2):\n",
    "    # randomly translate all images vertically and horizontally\n",
    "    # by -maxT to maxT.\n",
    "    Tv = random.binomial(maxT*2, 0.5) - maxT;\n",
    "    Th = random.binomial(maxT*2, 0.5) - maxT;\n",
    "    return roll(roll(X,Tv,axis=-2), Th, axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code shows an example of these permutations. Run it several times to see different random effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "img = trainI[4]\n",
    "noisefuncs = [add_gauss_noise, add_corrupt_noise, add_scale_shift, add_flip, add_translate]\n",
    "imgs = [img]\n",
    "titles = ['original image', 'Gaussian noise', 'corruption noise', 'scale and shift', 'flip', 'translate']\n",
    "for f in noisefuncs:\n",
    "    imgs.append(f(img))\n",
    "plt.figure(figsize=(8,6))\n",
    "show_imgs(imgs, nc=3, titles=titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is another example showing permutations of more data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# test methods on image stacks\n",
    "imgbatch = trainI[0:20].copy()\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(image_montage(imgbatch), cmap='gray', interpolation='nearest')\n",
    "plt.title('original')\n",
    "\n",
    "for i,f in enumerate(noisefuncs):\n",
    "    plt.figure()\n",
    "    plt.imshow(image_montage(f(imgbatch)), cmap='gray', interpolation='nearest')\n",
    "    plt.title(titles[i+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train your best CNN from the previous section using data augmentation. To do this, you need to define the `add_noise` function, and then use `callbacks_aug` as the callback function when creating the NN.\n",
    "\n",
    "Below is an example of an add_noise function. Try different types of data augmentation with different parameters, and combinations of them. Hopefully you should be able to improve the accuracy!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# here is an example add_noise function. It should return the permuted X.\n",
    "def add_noise(X):\n",
    "    return add_corrupt_noise(X, p=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### INSERT YOUR CODE HERE ###\n",
    "\n",
    "# NOTE: since we are permuting the data \"in-place\", you should train with\n",
    "# a copy of the data so that you don't mess up the original dataset.\n",
    "# Use the below call to the \"fit\" function\n",
    "cnn.fit(vtrainI.copy(), vtrainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Which type of augmentation improves the accuracy the most?  Why?_\n",
    "- **INSERT YOUR ANSWER HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test image\n",
    "Now lets try your face detector on a real image.  Download the \"nasa-small.png\" image and put it in the same directory as your ipynb file.  The below code will load the image, crop out image patches and then extract features. (this may take a few minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname = \"nasa-small.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load image\n",
    "testimg3 = skimage.io.imread(fname)\n",
    "\n",
    "# convert to grayscale\n",
    "testimg = skimage.color.rgb2gray(testimg3)\n",
    "print testimg.shape\n",
    "plt.imshow(testimg, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# step size for the sliding window\n",
    "step = 4\n",
    "\n",
    "# extract window patches with step size of 4\n",
    "patches = skimage.util.view_as_windows(testimg, (19,19), step=step)\n",
    "psize = patches.shape\n",
    "# collapse the first 2 dimensions\n",
    "patches2 = patches.reshape((psize[0]*psize[1], psize[2], psize[3]))\n",
    "print patches2.shape \n",
    "\n",
    "# histogram equalize patches (improves contrast)\n",
    "#newI = empty(patches2.shape)\n",
    "#for i in range(patches2.shape[0]):\n",
    "#    newI[i,:,:] = skimage.exposure.equalize_hist(patches2[i,:,:])\n",
    "newI = patches2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now predict using your classifier.  The extracted features are in `newXf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### YOUR CODE HERE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Now we we will view the results on the image.  Use the below code. `prednewY` is the vector of predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# reshape prediction to an image\n",
    "imgY = prednewY.reshape(psize[0], psize[1])\n",
    "\n",
    "# zoom back to image size\n",
    "imgY2 = ndimage.interpolation.zoom(imgY, step, output=None, order=0)\n",
    "# pad the top and left with half the window size\n",
    "imgY2 = vstack((zeros((9, imgY2.shape[1])), imgY2))\n",
    "imgY2 = hstack((zeros((imgY2.shape[0],9)), imgY2))\n",
    "# pad right and bottom to same size as image\n",
    "if (imgY2.shape[0] != testimg.shape[0]):\n",
    "    imgY2 = vstack((imgY2, zeros((testimg.shape[0]-imgY2.shape[0], imgY2.shape[1]))))\n",
    "if (imgY2.shape[1] != testimg.shape[1]):\n",
    "    imgY2 = hstack((imgY2, zeros((imgY2.shape[0],testimg.shape[1]-imgY2.shape[1]))))\n",
    "    \n",
    "# show detections with image\n",
    "detimg = dstack(((0.5*imgY2+0.5)*testimg, 0.5*testimg, 0.5*testimg))\n",
    "\n",
    "# show it!\n",
    "plt.figure(figsize=(9,9))\n",
    "plt.subplot(2,1,1)\n",
    "plt.imshow(imgY2, interpolation='nearest')\n",
    "plt.title('detection map')\n",
    "plt.subplot(2,1,2)\n",
    "plt.imshow(detimg)\n",
    "plt.title('image')\n",
    "plt.axis('image')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_How did your face detector do?_\n",
    "- **INSERT YOUR ANSWER HERE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- You can try it on your own images.  The faces should all be around 19x19 pixels though.\n",
    "- We only used 1/8 of the training data. Try using more data to train it!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
