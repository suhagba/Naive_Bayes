{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Name:** Byaravalli Arun Suhag\n",
    "\n",
    "**EID:** 53265857"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS4487 - Tutorial 10\n",
    "## Stochastic Gradient Descent\n",
    "\n",
    "In this tutorial you will use stochastic gradient descent to train classifiers quickly.\n",
    "\n",
    "First we need to initialize Python.  Run the below cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\sklearn\\lda.py:4: DeprecationWarning: lda.LDA has been moved to discriminant_analysis.LinearDiscriminantAnalysis in 0.17 and will be removed in 0.19\n",
      "  \"in 0.17 and will be removed in 0.19\", DeprecationWarning)\n",
      "C:\\Anaconda2\\lib\\site-packages\\sklearn\\qda.py:4: DeprecationWarning: qda.QDA has been moved to discriminant_analysis.QuadraticDiscriminantAnalysis in 0.17 and will be removed in 0.19.\n",
      "  \"in 0.17 and will be removed in 0.19.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import IPython.core.display         \n",
    "# setup output image format (Chrome works best)\n",
    "IPython.core.display.set_matplotlib_formats(\"svg\")\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from numpy import *\n",
    "from sklearn import *\n",
    "import glob\n",
    "import os\n",
    "import IPython.utils.warn as warn\n",
    "import cPickle, gzip, numpy\n",
    "import time\n",
    "\n",
    "random.seed(100)\n",
    "rbow = plt.get_cmap('rainbow')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a larger version of the MNIST digits dataset.  Download \"mnist.pkl.gz\" from Canvas and put it in the same directory as this ipynb file. The training set has 50,000 images and the test set has 10,000 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000L, 784L)\n",
      "(10000L, 784L)\n"
     ]
    }
   ],
   "source": [
    "# Load the dataset\n",
    "f = gzip.open('mnist.pkl.gz', 'rb')\n",
    "train_set, valid_set, test_set = cPickle.load(f)\n",
    "f.close()\n",
    "\n",
    "trainX,trainY = train_set\n",
    "valX,valY = valid_set\n",
    "testX,testY = test_set\n",
    "\n",
    "print trainX.shape\n",
    "print testX.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will train a linear SVM using the standard algorithm, and time how long it takes.  Run the below code.  It may take a few minutes to finish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time (sec): 67.0571290864\n"
     ]
    }
   ],
   "source": [
    "starttime = time.clock()\n",
    "clfo = svm.LinearSVC(C=1.0)\n",
    "clfo.fit(trainX, trainY)\n",
    "print \"elapsed time (sec):\", time.clock() - starttime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are the training and test errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM errors: 0.07384 0.0846\n"
     ]
    }
   ],
   "source": [
    "Ypred = clfo.predict(trainX)\n",
    "trainerr_svm = mean(Ypred != trainY)\n",
    "\n",
    "Ypred = clfo.predict(testX)\n",
    "testerr_svm = mean(Ypred != testY)\n",
    "print \"SVM errors:\", trainerr_svm, testerr_svm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD Classifier\n",
    "Now train a SGD classifier using the SVM loss and L2 penalty.  Time the amount of time it takes to fit the classifier (use the `fit` function).  Calculate the training and test error of the SGD classifier.  Use `alpha=0.1`.  Remember, alpha = 1/C."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### INSERT YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elapsed time (sec): 5.87798202469\n"
     ]
    }
   ],
   "source": [
    "starttime = time.clock()\n",
    "clf = linear_model.SGDClassifier(\n",
    "    loss='hinge',  # SVM loss (change to 'log' for logistic regression)\n",
    "    penalty='l2',  # standard penalty (change to 'l1' for feature selection)\n",
    "    alpha=1.0,     # penalty parameter: C=1/alpha \n",
    "    average=True)  # use a running average for classifier weights\n",
    "clf.fit(trainX, trainY)\n",
    "print \"elapsed time (sec):\", time.clock() - starttime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGDClassifier SVM errors: 0.21466 0.2007\n"
     ]
    }
   ],
   "source": [
    "Ypred = clf.predict(trainX)\n",
    "trainerr_sgdsvm = mean(Ypred != trainY)\n",
    "\n",
    "Ypred = clf.predict(testX)\n",
    "testerr_sgdsvm = mean(Ypred != testY)\n",
    "print \"SGDClassifier SVM errors:\", trainerr_sgdsvm, testerr_sgdsvm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_How does the speed and the accuracy compare with the original SVM?_\n",
    "- **The training with SGD using SVM and L2 penalty finishes in 5.8s and on the other hand svm alone takes around 67.1s. Thus we can clearly see that the former completes training faster**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel SGD Classifier\n",
    "Now train a parallel SGD classifier using IPython clusters, and measure the fitting time.  Use the same value for alpha as your SGD Classifier. Try different batch sizes (B) and number of processes (K).  Calculate the training and test error.\n",
    "\n",
    "First start the IP clusters using the \"IPython Clusters\" tab in Jupyter.  If the tab says \"Clusters tab now provided by IPython parallel\", then run `ipcluster nbextension enable` to enable it.  Alternatively, you can run  `ipcluster start -n 4` on the command line to directly start 4 clients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "# load the client interface\n",
    "import ipyparallel\n",
    "\n",
    "clients = ipyparallel.Client()\n",
    "clients.block = True   # wait for calculations to finish\n",
    "print clients.ids      # client process ids\n",
    "\n",
    "# get the load-balanced scheduler\n",
    "lview = clients.load_balanced_view()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[stderr:0] \n",
      "C:\\Anaconda2\\lib\\site-packages\\sklearn\\lda.py:4: DeprecationWarning: lda.LDA has been moved to discriminant_analysis.LinearDiscriminantAnalysis in 0.17 and will be removed in 0.19\n",
      "  \"in 0.17 and will be removed in 0.19\", DeprecationWarning)\n",
      "C:\\Anaconda2\\lib\\site-packages\\sklearn\\qda.py:4: DeprecationWarning: qda.QDA has been moved to discriminant_analysis.QuadraticDiscriminantAnalysis in 0.17 and will be removed in 0.19.\n",
      "  \"in 0.17 and will be removed in 0.19.\", DeprecationWarning)\n",
      "[stderr:1] \n",
      "C:\\Anaconda2\\lib\\site-packages\\sklearn\\lda.py:4: DeprecationWarning: lda.LDA has been moved to discriminant_analysis.LinearDiscriminantAnalysis in 0.17 and will be removed in 0.19\n",
      "  \"in 0.17 and will be removed in 0.19\", DeprecationWarning)\n",
      "C:\\Anaconda2\\lib\\site-packages\\sklearn\\qda.py:4: DeprecationWarning: qda.QDA has been moved to discriminant_analysis.QuadraticDiscriminantAnalysis in 0.17 and will be removed in 0.19.\n",
      "  \"in 0.17 and will be removed in 0.19.\", DeprecationWarning)\n",
      "[stderr:2] \n",
      "C:\\Anaconda2\\lib\\site-packages\\sklearn\\lda.py:4: DeprecationWarning: lda.LDA has been moved to discriminant_analysis.LinearDiscriminantAnalysis in 0.17 and will be removed in 0.19\n",
      "  \"in 0.17 and will be removed in 0.19\", DeprecationWarning)\n",
      "C:\\Anaconda2\\lib\\site-packages\\sklearn\\qda.py:4: DeprecationWarning: qda.QDA has been moved to discriminant_analysis.QuadraticDiscriminantAnalysis in 0.17 and will be removed in 0.19.\n",
      "  \"in 0.17 and will be removed in 0.19.\", DeprecationWarning)\n",
      "[stderr:3] \n",
      "C:\\Anaconda2\\lib\\site-packages\\sklearn\\lda.py:4: DeprecationWarning: lda.LDA has been moved to discriminant_analysis.LinearDiscriminantAnalysis in 0.17 and will be removed in 0.19\n",
      "  \"in 0.17 and will be removed in 0.19\", DeprecationWarning)\n",
      "C:\\Anaconda2\\lib\\site-packages\\sklearn\\qda.py:4: DeprecationWarning: qda.QDA has been moved to discriminant_analysis.QuadraticDiscriminantAnalysis in 0.17 and will be removed in 0.19.\n",
      "  \"in 0.17 and will be removed in 0.19.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "%%px\n",
    "# load libraries on all clients\n",
    "from numpy import *\n",
    "from sklearn import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### INSERT YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def par_sgd(data, param):\n",
    "    # run SGD on a dataset\n",
    "    clf = linear_model.SGDClassifier(\n",
    "        loss='hinge', \n",
    "        penalty='l2',\n",
    "        alpha=param['alpha'],\n",
    "        n_iter=10,       # number of epochs\n",
    "        average=False)  # don't use averaging, since we will do it later\n",
    "\n",
    "    clf.fit(data['trainX'], data['trainY'])\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def combine_sgd(clfs):\n",
    "    # combine sgd classifiers\n",
    "    \n",
    "    # make a copy of the first one\n",
    "    import copy\n",
    "    clfout = copy.deepcopy(clfs[0])\n",
    "    K = len(clfs)\n",
    "\n",
    "    # add all the remaining ones to it\n",
    "    for i in range(1,K):\n",
    "        clfout.coef_ += clfs[i].coef_\n",
    "        clfout.intercept_ += clfs[i].intercept_\n",
    "\n",
    "    # take the average\n",
    "    clfout.coef_ /= K\n",
    "    clfout.intercept_ /= K\n",
    "\n",
    "    return clfout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final classifier error: 0.13326\n",
      "individual clf errors:\n",
      "Classifier 1 : Error: 0.13296   \n",
      "Classifier 2 : Error: 0.13704   \n",
      "Classifier 3 : Error: 0.1338    \n",
      "Classifier 4 : Error: 0.13704   \n",
      "Classifier 5 : Error: 0.1348    \n",
      "Classifier 6 : Error: 0.13484   \n",
      "Classifier 7 : Error: 0.13916   \n",
      "Classifier 8 : Error: 0.13298   \n",
      "Classifier 9 : Error: 0.13436   \n",
      "Classifier 10: Error: 0.1332    \n",
      "elapsed time (sec): 46.2383533827\n"
     ]
    }
   ],
   "source": [
    "param = {'alpha': 0.1}\n",
    "\n",
    "K = 10           # use 10 processes\n",
    "N = len(trainX)  # dataset size\n",
    "B = int(0.25*N)  # batch size\n",
    "\n",
    "random.seed(612)\n",
    "\n",
    "starttime = time.clock()\n",
    "\n",
    "# split data into batches\n",
    "data_batches = []\n",
    "for i in range(K):\n",
    "    rp = random.permutation(N)\n",
    "    trainX_shuffle = trainX[rp[range(B)]]\n",
    "    trainY_shuffle = trainY[rp[range(B)]]\n",
    "    data_batches.append({'trainX': trainX_shuffle, 'trainY': trainY_shuffle})\n",
    "\n",
    "# run par_sgd on each batch of data\n",
    "lview.block = True\n",
    "clfs = lview.map(par_sgd, data_batches, [param]*K)\n",
    "\n",
    "# without load-balanced view (for testing)\n",
    "#clfs = map(par_sgd, data_batches, [param]*K)\n",
    "\n",
    "# combine classifiers\n",
    "clf = combine_sgd(clfs)  \n",
    "\n",
    "# training error\n",
    "Ypred = clf.predict(trainX)\n",
    "err = mean(Ypred != trainY)\n",
    "print \"final classifier error:\", err\n",
    "\n",
    "# compare with individual classifiers\n",
    "errs = []\n",
    "for myclf in clfs:\n",
    "    mypred = myclf.predict(trainX)\n",
    "    errs.append( mean(mypred != trainY) )\n",
    "\n",
    "print \"individual clf errors:\"\n",
    "for i, err in enumerate(errs):\n",
    "    print \"Classifier %-2s: Error: %-10s\" %(str(i + 1), str(err))\n",
    "    \n",
    "print \"elapsed time (sec):\", time.clock() - starttime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_How does the speed and the accuracy compare with the original SVM?_\n",
    "- **The error for original SVM is less than the later but the training time for the original SVM is more than the later.**\n",
    "- **Original SVM : traing time= 67.1s  and error = 0.07**\n",
    "- **Parallel SGD classifier : traing time= 46s  and error = 0.13326**\n",
    "\n",
    "Thus we can clearly see from the above experiment that their is a trade-off between time and accuracy \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
